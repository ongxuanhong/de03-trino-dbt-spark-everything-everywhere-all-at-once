version: "3.9"

services:

  de_mysql:
    image: "mariadb"
    container_name: de_mysql
    volumes:
      - ./mysql:/var/lib/mysql
    ports:
      - "3306:3306"
    env_file:
      - .env
    networks:
      - data_network

  de_psql:
    image: postgres:15
    container_name: de_psql
    volumes:
      - ./psql:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    env_file:
      - .env
    networks:
      - data_network

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    volumes:
      - ./minio/data:/data
    env_file:
      - .env
    networks:
      - data_network

  hive-metastore:
    container_name: hive-metastore
    hostname: hive-metastore
    image: "bitsondatadev/hive-metastore"
    ports:
      - "9083:9083"
    volumes:
      - ./hive-metastore/metastore-site.xml:/opt/apache-hive-metastore-3.0.0-bin/conf/metastore-site.xml:ro
    environment:
      METASTORE_DB_HOSTNAME: de_mysql
    networks:
      - data_network
    depends_on:
      - de_mysql
      - minio

  trino:
    container_name: trino
    image: "trinodb/trino"
    hostname: trino
    ports:
      - "8080:8080"
    volumes:
      - ./trino:/etc/trino
    networks:
      - data_network

  spark-master:
    build:
      context: ./spark
      dockerfile: ./Dockerfile
    image: de03/spark
    container_name: "spark-master"
    command: sh -c "/opt/spark/sbin/start-master.sh && tail -f /dev/null"
    environment:
      - SPARK_MODE=master
      - SPARK_LOCAL_IP=spark-master
    ports:
      - "7077:7077"
      - "8081:8080"
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - data_network

  spark-worker-1:
    image: de03/spark
    container_name: "spark-worker-1"
    command: sh -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - data_network

  spark-worker-2:
    image: de03/spark
    container_name: "spark-worker-2"
    command: sh -c "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 && tail -f /dev/null"
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - data_network

  spark-thrift-server:
    image: de03/spark
    container_name: "spark-thrift-server"
    command: sh -c "/opt/spark/sbin/start-thriftserver.sh --driver-java-options '-Dhive.metastore.uris=thrift://hive-metastore:9083' --master spark://spark-master:7077 && tail -f /dev/null"
    depends_on:
      - spark-master
      - hive-metastore
    ports:
      - "4040:4040"
      - "10000:10000"
    volumes:
      - ./spark/spark-defaults.conf:/opt/spark/conf/spark-defaults.conf
    networks:
      - data_network

  metabase:
    image: metabase/metabase:latest
    container_name: "metabase"
    ports:
      - "3000:3000"
    env_file:
      - .env
    networks:
      - data_network

networks:
  data_network:
    driver: bridge
    name: data_network
